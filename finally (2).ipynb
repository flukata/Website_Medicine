{"cells":[{"cell_type":"markdown","id":"50e156f9-a523-4947-936c-114dc9ead59f","metadata":{"id":"50e156f9-a523-4947-936c-114dc9ead59f"},"source":["# Problem and Pain point\n","  ปัจจุบัน มีคนจำนวนมากประสบปัญหาในการอ่านชื่อยาไม่ทราบสรรพคุณของยาและข้อควรระวัง สาเหตุเกิดจากภาษาและคำศัพท์เฉพาะทางการแพทย์ที่เข้าใจยาก ทำให้เกิดความสับสนและอาจนำไปสู่การใช้ยาผิดวิธี ซึ่งส่งผลเสียต่อสุขภาพได้ อีกทั้งยาบางชนิดเมื่อพิมพ์ค้นหาเพียงชื่อสามัญ (generic name) อาจให้ผลลัพธ์ที่ไม่ชัดเจน เนื่องจากมีหลายตัวยาหรือหลายสูตรตำรับที่คล้ายกัน ดังนั้น Mediscan จึงจัดทำขึ้นเพื่อแก้ไขปัญหาดังกล่าว โดยพัฒนา AI ที่ช่วยให้ผู้ใช้งานสามารถพิมพ์ชื่อสามัญของยาที่ต้องการทราบข้อมูลหรือเพียงถ่ายภาพแผงยา,ฉลากยา ระบบจะทำการแสดงรายละเอียดของยา คือ ชื่อยา ข้อบ่งชี้ วิธีใช้ และข้อควรระวัง เพื่ออำนวยความสะดวกให้แก่ผู้ใช้งาน ช่วยให้สามารถเข้าถึงข้อมูลยาได้อย่างรวดเร็ว ถูกต้อง และลดความผิดพลาดจากการใช้ยา\n","\n","  "]},{"cell_type":"code","execution_count":1,"id":"eJofjjO-aqED","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28897,"status":"ok","timestamp":1759888077856,"user":{"displayName":"1053 Siraphon Sangmanee","userId":"11925174942605310203"},"user_tz":-420},"id":"eJofjjO-aqED","outputId":"803df359-8154-4988-94e3-cab118d7ee02"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","id":"d46dd0bd-1839-4def-b071-597d7cca01d3","metadata":{"id":"d46dd0bd-1839-4def-b071-597d7cca01d3"},"source":["## Data source (image)\n","###### https://kmitlthailand-my.sharepoint.com/:x:/g/personal/66051053_kmitl_ac_th/EdKW5praf75JktRZlNOoY5EBIpljG9GNQ24P8GNiv_pi7A?e=s4ctAV"]},{"cell_type":"markdown","id":"59096d5e-bbec-45e1-bae5-58cc6ca58ef9","metadata":{"id":"59096d5e-bbec-45e1-bae5-58cc6ca58ef9"},"source":["## Data Cleaning\n","###### https://kmitlthailand-my.sharepoint.com/:x:/g/personal/66051053_kmitl_ac_th/EQlK4rZ58_1Bq6tqwJuMuBgB9p-Ztt2hUWdmJ3Vx1fgFjw?e=DVu2b0"]},{"cell_type":"markdown","id":"d4a7c70d-fea4-46d8-8c51-d7a4238ed5b6","metadata":{"id":"d4a7c70d-fea4-46d8-8c51-d7a4238ed5b6"},"source":["### Library version ที่ใช้\n","-pandas: 2.3.2\n","-numpy: 1.26.4\n","-scikit-learn: 1.6.1\n","-matplotlib: 3.9.4\n","-seaborn: 0.13.2\n","-imblearn: 0.12.4\n"]},{"cell_type":"code","execution_count":2,"id":"ef8b3613-8c6b-42f1-b5ca-6e812eee4c79","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3254,"status":"ok","timestamp":1759888081105,"user":{"displayName":"1053 Siraphon Sangmanee","userId":"11925174942605310203"},"user_tz":-420},"id":"ef8b3613-8c6b-42f1-b5ca-6e812eee4c79","outputId":"95a84d71-b34d-4977-d9be-910cf89f1fa5"},"outputs":[{"name":"stdout","output_type":"stream","text":["pandas: 2.2.2\n","numpy: 2.0.2\n","scikit-learn: 1.6.1\n","matplotlib: 3.10.0\n","imblearn: 0.14.0\n"]}],"source":["# Import Library ที่สำคัญ\n","import pandas as pd\n","import numpy as np\n","import sklearn\n","import matplotlib\n","import imblearn\n","\n","print(\"pandas:\", pd.__version__)\n","print(\"numpy:\", np.__version__)\n","print(\"scikit-learn:\", sklearn.__version__)\n","print(\"matplotlib:\", matplotlib.__version__)\n","print(\"imblearn:\", imblearn.__version__)"]},{"cell_type":"code","execution_count":3,"id":"491941ec-9a92-4ff7-8c2a-b7cd2a0b00bd","metadata":{"executionInfo":{"elapsed":4948,"status":"ok","timestamp":1759888086048,"user":{"displayName":"1053 Siraphon Sangmanee","userId":"11925174942605310203"},"user_tz":-420},"id":"491941ec-9a92-4ff7-8c2a-b7cd2a0b00bd"},"outputs":[],"source":["# Import library ที่สำคัญ\n","# การคำนวณพื้นฐานและจัดการข้อมูล (Numerical \u0026 Data Handling)\n","import numpy as np               # ใช้จัดการข้อมูลตัวเลขและ array\n","import pandas as pd              # ใช้จัดการข้อมูลในรูปแบบตาราง DataFrame\n","\n","# การแสดงผล (Visualization)\n","import matplotlib\n","import matplotlib.pyplot as plt  # สำหรับสร้างกราฟ Accuracy / Loss / Confusion Matrix\n","import seaborn as sns            # ใช้ตกแต่งกราฟให้อ่านง่าย\n","\n","# TensorFlow สำหรับการสร้างโมเดล\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","# Scikit-learn สำหรับการสร้างโมเดล Machine Learning\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression, SGDClassifier\n","from sklearn.metrics import (\n","    accuracy_score,\n","    classification_report,\n","    confusion_matrix,\n","    log_loss\n",")\n","\n","# การจัดการข้อมูลไม่สมดุล (Data Balancing)\n","from imblearn.over_sampling import SMOTE, RandomOverSampler\n","\n","# ฟังก์ชันทั่วไป (Utility)\n","import random\n","import re\n"]},{"cell_type":"code","execution_count":4,"id":"a107f1eb-221b-4d27-af09-d2c740bf3806","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9025,"status":"ok","timestamp":1759888095076,"user":{"displayName":"1053 Siraphon Sangmanee","userId":"11925174942605310203"},"user_tz":-420},"id":"a107f1eb-221b-4d27-af09-d2c740bf3806","outputId":"27ded55b-d3d4-4bd7-c640-75355f7ca26c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n","Requirement already satisfied: numpy\u003c3,\u003e=1.25.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (2.0.2)\n","Requirement already satisfied: scipy\u003c2,\u003e=1.11.4 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.16.2)\n","Requirement already satisfied: scikit-learn\u003c2,\u003e=1.4.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.6.1)\n","Requirement already satisfied: joblib\u003c2,\u003e=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.5.2)\n","Requirement already satisfied: threadpoolctl\u003c4,\u003e=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (3.6.0)\n"]}],"source":["pip install imbalanced-learn"]},{"cell_type":"markdown","id":"0564eb6c-a34b-4847-bf6f-76f43b54c174","metadata":{"id":"0564eb6c-a34b-4847-bf6f-76f43b54c174"},"source":["## Train 1 (Data Cleaning)"]},{"cell_type":"code","execution_count":null,"id":"zqcMz9Cvbh7W","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":39},"id":"zqcMz9Cvbh7W"},"outputs":[{"data":{"text/html":["\n","     \u003cinput type=\"file\" id=\"files-a83e72d1-d4d5-4829-bad6-0959e2c32c39\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" /\u003e\n","     \u003coutput id=\"result-a83e72d1-d4d5-4829-bad6-0959e2c32c39\"\u003e\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      \u003c/output\u003e\n","      \u003cscript\u003e// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) =\u003e {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable\u003c!Object\u003e} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) =\u003e {\n","    inputElement.addEventListener('change', (e) =\u003e {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) =\u003e {\n","    cancel.onclick = () =\u003e {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) =\u003e {\n","      const reader = new FileReader();\n","      reader.onload = (e) =\u003e {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position \u003c fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","\u003c/script\u003e "],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"ename":"TypeError","evalue":"'NoneType' object is not subscriptable","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-264872163.py\u001b[0m in \u001b[0;36m\u003ccell line: 0\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 171\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     result = _output.eval_js(\n\u001b[1;32m    173\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n","\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"]}],"source":["from google.colab import files\n","uploaded = files.upload()\n"]},{"cell_type":"code","execution_count":null,"id":"08236e80-8360-40a5-9c0a-e4aa95491833","metadata":{"colab":{"background_save":true},"id":"08236e80-8360-40a5-9c0a-e4aa95491833"},"outputs":[],"source":["import pandas as pd\n","\n","df = pd.read_excel(\"leaflet(1).xlsx\")\n","print(df.columns.tolist())"]},{"cell_type":"code","execution_count":null,"id":"6f7a2cb2-91c2-43fa-aaf1-b42dcd554166","metadata":{"colab":{"background_save":true},"id":"6f7a2cb2-91c2-43fa-aaf1-b42dcd554166","scrolled":true},"outputs":[],"source":["!pip install seaborn"]},{"cell_type":"code","execution_count":null,"id":"a196dca6-fa09-4bac-8c6a-9563460a3683","metadata":{"colab":{"background_save":true},"id":"a196dca6-fa09-4bac-8c6a-9563460a3683"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import random\n","import re\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from imblearn.over_sampling import RandomOverSampler"]},{"cell_type":"code","execution_count":null,"id":"f722f8a7-e090-4592-ad35-fe0fed849749","metadata":{"colab":{"background_save":true},"id":"f722f8a7-e090-4592-ad35-fe0fed849749","scrolled":true},"outputs":[],"source":["df = pd.read_excel(\"leaflet(1).xlsx\")\n","\n","# ตรวจสอบข้อมูลเบื้องต้น\n","print(df.head())\n","print(df.info())"]},{"cell_type":"code","execution_count":null,"id":"a83c42ad-1cd4-4476-ac46-a720b9af389b","metadata":{"colab":{"background_save":true},"id":"a83c42ad-1cd4-4476-ac46-a720b9af389b"},"outputs":[],"source":["# กำหนดคอลัมน์ที่ต้องการรวมเป็นข้อความ\n","text_cols = ['generics', 'dosage_strengths', 'indications', 'instructions', 'warnings']\n","\n","# แปลงเป็นสตริงและ สตริงว่างเติมค่าแทน NaN ก่อนรวม\n","for c in text_cols:\n","    df[c] = df[c].fillna('').astype(str)\n","\n","# รวมข้อความเป็นคอลัมน์text\n","df['text'] = df[text_cols].agg(' '.join, axis=1)\n","\n","# เอาเฉพาะแถวที่มี label (generics) จริง ๆ\n","df = df[df['generics'].str.strip() != '']"]},{"cell_type":"code","execution_count":null,"id":"2023fdce-0749-40b5-ac12-2d017c380725","metadata":{"colab":{"background_save":true},"id":"2023fdce-0749-40b5-ac12-2d017c380725"},"outputs":[],"source":["from imblearn.over_sampling import RandomOverSampler"]},{"cell_type":"code","execution_count":null,"id":"8de3333e-6c60-488e-b55c-5f4d85adf728","metadata":{"colab":{"background_save":true},"id":"8de3333e-6c60-488e-b55c-5f4d85adf728"},"outputs":[],"source":["#แยกฟีเจอร์และเลเบล แบ่งเป็นแบบ train test โดยรักษาสัดส่วนแต่ละคลาส (stratify)\n","X = df['text']\n","y = df['generics']\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.3, stratify=y, random_state=42\n",")\n"]},{"cell_type":"code","execution_count":null,"id":"3edb2b53-bf3a-4338-847f-84663c90fb94","metadata":{"colab":{"background_save":true},"id":"3edb2b53-bf3a-4338-847f-84663c90fb94"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression"]},{"cell_type":"code","execution_count":null,"id":"b4aec07c-1461-43af-8eb9-852010d1b245","metadata":{"colab":{"background_save":true},"collapsed":true,"id":"b4aec07c-1461-43af-8eb9-852010d1b245","scrolled":true},"outputs":[],"source":["vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n","X_train_tfidf = vectorizer.fit_transform(X_train)\n","X_test_tfidf  = vectorizer.transform(X_test)\n","\n","from imblearn.over_sampling import RandomOverSampler\n","ros = RandomOverSampler(random_state=42)\n","X_resampled, y_resampled = ros.fit_resample(X_train_tfidf, y_train)\n","\n","from sklearn.linear_model import LogisticRegression\n","model = LogisticRegression(solver='saga', max_iter=300, tol=1e-3)\n","model.fit(X_resampled, y_resampled)\n","\n","y_pred = model.predict(X_test_tfidf)\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(classification_report(y_test, y_pred, digits=4, zero_division=0))\n"]},{"cell_type":"code","execution_count":null,"id":"0d3842e2-965f-4963-808d-0e9333171526","metadata":{"colab":{"background_save":true},"id":"0d3842e2-965f-4963-808d-0e9333171526"},"outputs":[],"source":["if 'df' not in globals():\n","    import pandas as pd\n","    df = pd.read_excel('leaflet(1).xlsx')\n","\n","need_text = 'text' not in df.columns\n","if need_text:\n","    for c in ['generics','dosage_strengths','indications','instructions','warnings']:\n","        if c in df.columns:\n","            df[c] = df[c].fillna('').astype(str)\n","        else:\n","            df[c] = ''  # กันพลาดกรณีคอลัมน์ขาด\n","    df['text'] = (df['generics'] + ' ' + df['dosage_strengths'] + ' ' +\n","                  df['indications'] + ' ' + df['instructions'] + ' ' +\n","                  df['warnings'])\n","\n","if 'X_train' not in globals() or 'y_train' not in globals():\n","    from sklearn.model_selection import train_test_split\n","    X = df['text']\n","    y = df['generics'].astype(str)\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=0.3, stratify=y, random_state=42\n","    )\n","\n","if 'X_train_tfidf' not in globals():\n","    from sklearn.feature_extraction.text import TfidfVectorizer\n","    vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1,2))\n","    X_train_tfidf = vectorizer.fit_transform(X_train)\n","\n","random_state=42\n","from imblearn.over_sampling import RandomOverSampler\n","ros = RandomOverSampler(random_state=42)\n","X_resampled, y_resampled = ros.fit_resample(X_train_tfidf, y_train)\n","\n","#print(\"✅ พร้อมแล้ว:\")\n","print(\"X_resampled:\", X_resampled.shape, \"| y_resampled:\", y_resampled.shape)\n"]},{"cell_type":"code","execution_count":null,"id":"5a666c44-b18e-4ebe-8363-607db4bd93e5","metadata":{"colab":{"background_save":true},"id":"5a666c44-b18e-4ebe-8363-607db4bd93e5","scrolled":true},"outputs":[],"source":["whos"]},{"cell_type":"markdown","id":"c4d324a2-0298-4f0d-a98c-5ee96ba55021","metadata":{"id":"c4d324a2-0298-4f0d-a98c-5ee96ba55021"},"source":["## epoch"]},{"cell_type":"markdown","id":"ea5825aa-2775-4faa-83e4-c41261ec7e28","metadata":{"id":"ea5825aa-2775-4faa-83e4-c41261ec7e28"},"source":["## ปรับปรุงกราฟของ Data Cleaning\n","###### log_loss เพี้ยน เพราะใช้ labels ไม่ตรงกับลำดับโปรบาบิลิตี\n","###### predict_proba ของโมเดลเรียงคอลัมน์ตาม sgd.classes_\n","###### ชุดที่ใช้วัดผลไม่ชัด (ตัวแปร X_tr/X_val) อ้าง X_tr, y_tr, X_val, y_val แต่ไม่ได้ล็อกนิยามให้ชัดเจน\n","###### กำหนด classes = np.unique(y_resampled) อาจไม่ครอบคลุมคลาสใน y_val บางตัว"]},{"cell_type":"code","execution_count":null,"id":"3ac6748c-156c-4a26-b548-d0ba202a382d","metadata":{"colab":{"background_save":true},"id":"3ac6748c-156c-4a26-b548-d0ba202a382d","scrolled":true},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, log_loss\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","\n","# 1) แบ่ง Train/Validation จากชุดที่ oversample มาแล้ว\n","X_tr, X_val, y_tr, y_val = train_test_split(\n","    X_resampled, y_resampled, test_size=0.3, random_state=42, stratify=y_resampled\n",")\n","\n","# 2) ตั้งค่า Logistic Regression (เทรนแบบ incremental)\n","epochs = 10  # จำนวนรอบเทรน\n","model_epoch = LogisticRegression(\n","    solver='saga',         # รองรับ sparse matrix ได้ดี\n","    penalty='l2',          # เพิ่ม regularization ให้เสถียร\n","    C=1.0,                 # ลดค่าถ้า overfitting (0.5, 0.1)\n","    max_iter=1,            # เทรนครั้งละ 1 iteration ต่อ epoch\n","    warm_start=True,       # ต่อจากน้ำหนักเดิมทุก epoch\n","    n_jobs=-1,             # ใช้หลาย core เพื่อความเร็ว\n","    random_state=42\n",")\n","\n","train_loss, val_loss, train_acc, val_acc = [], [], [], []\n","\n","# 3) วนเทรนหลาย epoch\n","for ep in range(1, epochs+1):\n","    model_epoch.fit(X_tr, y_tr)\n","\n","    # ---- Train metrics ----\n","    ytr_pred = model_epoch.predict(X_tr)\n","    ytr_prob = model_epoch.predict_proba(X_tr)\n","    acc_tr   = accuracy_score(y_tr, ytr_pred)\n","    loss_tr  = log_loss(y_tr, ytr_prob, labels=model_epoch.classes_)\n","\n","    # ---- Validation metrics ----\n","    yv_pred = model_epoch.predict(X_val)\n","    yv_prob = model_epoch.predict_proba(X_val)\n","    acc_val = accuracy_score(y_val, yv_pred)\n","    loss_val = log_loss(y_val, yv_prob, labels=model_epoch.classes_)\n","\n","    # ---- เก็บค่า ----\n","    train_acc.append(acc_tr)\n","    val_acc.append(acc_val)\n","    train_loss.append(loss_tr)\n","    val_loss.append(loss_val)\n","\n","    print(f\"Epoch {ep:02d}/{epochs} | \"\n","          f\"acc_tr={acc_tr:.4f} acc_val={acc_val:.4f} | \"\n","          f\"loss_tr={loss_tr:.4f} loss_val={loss_val:.4f}\")\n","\n","# 4) กราฟ Loss ต่อ epoch\n","plt.figure(figsize=(9,4))\n","plt.plot(range(1, epochs+1), train_loss, marker='o', label='Training Loss')\n","plt.plot(range(1, epochs+1), val_loss, marker='o', label='Validation Loss')\n","plt.title('Log Loss per Epoch')\n","plt.xlabel('Epoch'); plt.ylabel('Log Loss')\n","plt.grid(True); plt.legend(); plt.show()\n","\n","# 5) กราฟ Accuracy ต่อ epoch\n","plt.figure(figsize=(9,4))\n","plt.plot(range(1, epochs+1), train_acc, marker='o', label='Training Accuracy')\n","plt.plot(range(1, epochs+1), val_acc, marker='o', label='Validation Accuracy')\n","plt.title('Accuracy per Epoch')\n","plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n","plt.grid(True); plt.legend(); plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"dcf435f3-ac12-40d9-bea7-524ba3252d68","metadata":{"colab":{"background_save":true},"id":"dcf435f3-ac12-40d9-bea7-524ba3252d68"},"outputs":[],"source":["from sklearn.linear_model import SGDClassifier\n","from sklearn.metrics import accuracy_score, log_loss\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# ===== ตั้งค่า =====\n","epochs = 10\n","batch_size = 2048\n","classes = np.unique(y_resampled)\n","\n","# ===== โมเดล =====\n","sgd = SGDClassifier(\n","    loss='log_loss',\n","    alpha=1e-4,\n","    learning_rate='optimal',\n","    early_stopping=False,\n","    class_weight=None,\n","    random_state=42\n",")\n","\n","# ===== เตรียมเก็บค่าเพื่อพล็อต =====\n","train_acc_list, val_acc_list = [], []\n","train_loss_list, val_loss_list = [], []\n","\n","# ===== เริ่มเทรน =====\n","n = X_resampled.shape[0]\n","for ep in range(1, epochs+1):\n","    # shuffle index ทุก epoch\n","    idx = np.random.permutation(n)\n","    X_shuf = X_resampled[idx]\n","    y_shuf = y_resampled.iloc[idx] if hasattr(y_resampled, \"iloc\") else y_resampled[idx]\n","\n","    # mini-batch training\n","    start = 0\n","    while start \u003c n:\n","        end = min(start + batch_size, n)\n","        Xb, yb = X_shuf[start:end], y_shuf[start:end]\n","        if ep == 1 and start == 0:\n","            sgd.partial_fit(Xb, yb, classes=classes)\n","        else:\n","            sgd.partial_fit(Xb, yb)\n","        start = end\n","\n","    # ==== คำนวณ metric ต่อ epoch ====\n","    ytr = sgd.predict(X_tr)\n","    ytrp = sgd.predict_proba(X_tr)\n","    yv = sgd.predict(X_val)\n","    yvp = sgd.predict_proba(X_val)\n","\n","    acc_tr = accuracy_score(y_tr, ytr)\n","    acc_val = accuracy_score(y_val, yv)\n","    loss_tr = log_loss(y_tr, ytrp, labels=classes)\n","    loss_val = log_loss(y_val, yvp, labels=classes)\n","\n","    train_acc_list.append(acc_tr)\n","    val_acc_list.append(acc_val)\n","    train_loss_list.append(loss_tr)\n","    val_loss_list.append(loss_val)\n","\n","    print(f\"[SGD] Epoch {ep:02d}/{epochs} | \"\n","          f\"acc_tr={acc_tr:.6f} acc_val={acc_val:.6f} | \"\n","          f\"loss_tr={loss_tr:.6f} loss_val={loss_val:.6f}\")\n","\n","# ===== พล็อตกราฟหลังเทรนเสร็จ =====\n","epochs_range = range(1, epochs + 1)\n","\n","# --- Loss ---\n","plt.figure(figsize=(9,4))\n","plt.plot(epochs_range, train_loss_list, marker='o', label='Training Loss')\n","plt.plot(epochs_range, val_loss_list, marker='o', label='Validation Loss')\n","plt.title('SGDClassifier - Log Loss per Epoch')\n","plt.xlabel('Epoch')\n","plt.ylabel('Log Loss')\n","plt.grid(True)\n","plt.legend()\n","plt.show()\n","\n","# --- Accuracy ---\n","plt.figure(figsize=(9,4))\n","plt.plot(epochs_range, train_acc_list, marker='o', label='Training Accuracy')\n","plt.plot(epochs_range, val_acc_list, marker='o', label='Validation Accuracy')\n","plt.title('SGDClassifier - Accuracy per Epoch')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.grid(True)\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"markdown","id":"1788fb01-e752-4867-b716-03be1e0393ff","metadata":{"id":"1788fb01-e752-4867-b716-03be1e0393ff"},"source":["# Data Set Augmentation"]},{"cell_type":"code","execution_count":null,"id":"5365f7fe-3d67-4710-9a43-38ebf607b36b","metadata":{"colab":{"background_save":true},"id":"5365f7fe-3d67-4710-9a43-38ebf607b36b"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import random\n","import re\n","\n","# -----------------------------\n","# ตั้งค่า\n","# -----------------------------\n","SRC_PATH  = \"leaflet(1).xlsx\"         # ไฟล์ต้นทาง\n","SHEET     = None                      # ถ้ารู้ชื่อชีตให้ใส่ เช่น \"leaflet\" ไม่งั้นปล่อย None = ชีตแรก\n","OUT_PATH  = \"leaflet_train.xlsx\"  # ไฟล์ผลลัพธ์\n","N_ADD_PER_CLASS = 500                 # จำนวน \"แถวใหม่\" ต่อคลาส\n","ERROR_RATE       = 0.05               # สัดส่วน error ต่อคลาส (0.05 = 5%)\n","\n","# -----------------------------\n","# ตัวช่วยอ่านชีต\n","# -----------------------------\n","def load_excel(path, sheet=None):\n","    if sheet is not None:\n","        return pd.read_excel(path, sheet_name=sheet)\n","    # ถ้าไม่ระบุชีต → อ่านชีตแรก\n","    xls = pd.ExcelFile(path)\n","    first = xls.sheet_names[0]\n","    return pd.read_excel(path, sheet_name=first)\n","\n","# -----------------------------\n","# โหลดไฟล์\n","# -----------------------------\n","df = load_excel(SRC_PATH, sheet=SHEET)\n","\n","# normalize ชื่อคอลัมน์ (ลบช่องว่างหัวท้าย + lower ไว้หาตำแหน่งคอลัมน์)\n","col_map = {c: c.strip() if isinstance(c, str) else c for c in df.columns}\n","df = df.rename(columns=col_map)\n","lower_cols = {c.lower(): c for c in df.columns if isinstance(c, str)}\n","\n","# คอลัมน์หลัก\n","if \"generics\" not in lower_cols:\n","    raise ValueError(\"ไม่พบคอลัมน์ชื่อยา 'generics' ในไฟล์ Excel\")\n","GENERIC_COL = lower_cols[\"generics\"]\n","\n","# หา target columns ที่มีจริงในไฟล์ (รองรับทั้งบางส่วน/ทั้งหมด)\n","candidate_targets = [\"dosage_strength\", \"instructions\", \"warnings\", \"indications\"]\n","TARGET_COLS = [lower_cols[c] for c in candidate_targets if c in lower_cols]\n","\n","if not TARGET_COLS:\n","    print(\"คำเตือน: ไม่พบคอลัมน์เป้าหมาย (dosage_strength / instructions / warnings / indications) — จะสร้างเฉพาะแถวใหม่โดยยกค่าจาก seed\")\n","else:\n","    print(\"จะทำ variation ให้คอลัมน์:\", TARGET_COLS)\n","\n","# -----------------------------\n","# รวมชื่อ variant เป็น class เดียว\n","# -----------------------------\n","def canonical_generic(name: str) -\u003e str:\n","    if pd.isna(name):\n","        return \"\"\n","    s = str(name).lower().strip()\n","    s = re.sub(r\"\\s+\", \" \", s)\n","    # รวม salt/spelling/ภาษาไทยเป็นคลาสเดียว\n","    s = s.replace(\"แอมโลดิพีน\", \"amlodipine\")\n","    s = s.replace(\"แอมโลดิพีน เบซิเลต\", \"amlodipine besylate\")\n","    s = s.replace(\"besilate\", \"besylate\")\n","    # เอาคำว่า besylate ออก เพื่อให้ amlodipine และ amlodipine besylate รวมเป็น class เดียว\n","    s = s.replace(\"besylate\", \"\")\n","    # กวาดสัญลักษณ์/วงเล็บ\n","    s = re.sub(r\"[()\\-_.]\", \" \", s)\n","    s = re.sub(r\"\\s+\", \" \", s).strip()\n","    return s\n","\n","df[\"_class_key\"] = df[GENERIC_COL].map(canonical_generic)\n","\n","# -----------------------------\n","# พจนานุกรมคำสลับ (ทั้งไทย/อังกฤษ)\n","# -----------------------------\n","SYN_RULES = [\n","    (r\"\\bผู้ใหญ่\\b\", [\"คนโต\", \"ผู้ป่วยผู้ใหญ่\"]),\n","    (r\"\\bเด็ก\\b\", [\"ผู้เยาว์\", \"เด็กเล็ก\"]),\n","    (r\"มิลลิกรัม\\b\", [\"มก.\", \"มก\", \"milligram\", \"mg\"]),\n","    (r\"\\bmg\\b\", [\"มก\", \"milligram\", \"มก.\"]),\n","    (r\"\\bชั่วโมง\\b\", [\"ชม.\", \"ชั่วโมงละ\", \"ต่อชั่วโมง\"]),\n","    (r\"\\bต่อวัน\\b\", [\"/วัน\", \"ต่อ 24 ชั่วโมง\"]),\n","    (r\"\\bรับประทาน\\b\", [\"ทาน\", \"กิน\"]),\n","    (r\"\\bควรใช้\\b\", [\"ควรจะใช้\", \"แนะนำให้ใช้\"]),\n","    (r\"\\bห้ามใช้\\b\", [\"ห้าม\", \"ไม่ควรใช้\"]),\n","    (r\"\\bความดันโลหิตสูง\\b\", [\"HT\", \"Hypertension\"]),\n","    (r\"\\bโรคหลอดเลือดหัวใจตีบ\\b\", [\"กล้ามเนื้อหัวใจขาดเลือด\", \"Angina Pectoris\"]),\n","    (r\"\\bCAD\\b\", [\"โรคหลอดเลือดหัวใจตีบที่ได้รับการวินิจฉัยแล้ว\", \"Coronary Artery Disease\"]),\n","    (r\"\\bระมัดระวัง\\b\", [\"ควรระวัง\", \"ใช้ด้วยความระวัง\"]),\n","]\n","\n","# -----------------------------\n","# ตัวช่วยปรับคำ/หน่วย/ตัวเลข\n","# -----------------------------\n","def apply_synonyms(text: str, max_rules: int = 3, p_apply: float = 0.6) -\u003e str:\n","    if not isinstance(text, str) or not text.strip():\n","        return text\n","    out = text\n","    # ใช้สุ่มได้สูงสุด max_rules รายการต่อข้อความ\n","    rules = random.sample(SYN_RULES, k=min(max_rules, len(SYN_RULES)))\n","    for pat, repls in rules:\n","        if random.random() \u003c p_apply and re.search(pat, out):\n","            out = re.sub(pat, random.choice(repls), out)\n","    return out\n","\n","\n","def tweak_numbers(text: str, p_apply: float = 0.35) -\u003e str:\n","    if not isinstance(text, str) or not text.strip():\n","        return text\n","    if random.random() \u003e= p_apply:\n","        return text\n","\n","def small_typo(text: str) -\u003e str:\n","    \"\"\"สุ่มพิมพ์ผิดเล็กน้อย 1 จุด (สำหรับ error \u003c= 5%)\"\"\"\n","    if not isinstance(text, str) or len(text) \u003c 3:\n","        return text\n","    i = random.randrange(len(text))\n","    c = text[i]\n","    repl = {\n","        \"0\": \"O\", \"O\": \"0\", \"1\": \"l\", \"l\": \"1\", \"i\": \"1\", \"g\": \"9\", \"9\": \"g\",\n","        \"ี\": \"ิ\", \"้\": \"๊\", \"า\": \"ำ\"\n","    }.get(c, None)\n","    if repl is None:\n","        # ลบทิ้ง 1 ตัวอักษร\n","        return text[:i] + text[i+1:]\n","    return text[:i] + repl + text[i+1:]\n","\n","    def bump_num(m):\n","        num = m.group(0)\n","        try:\n","            if \"-\" in num:\n","                a, b = num.split(\"-\")\n","                a = str(max(1, int(a) + random.choice([-1, 0, 1])))\n","                b = str(max(1, int(b) + random.choice([-1, 0, 1])))\n","                return f\"{a}-{b}\"\n","            else:\n","                return str(max(1, int(num) + random.choice([-1, 0, 1])))\n","        except:\n","            return num\n","\n","    return re.sub(r\"\\d+\\-\\d+|\\d+\", bump_num, text)\n","\n","# -----------------------------\n","# สร้างแถวใหม่ต่อคลาส\n","# -----------------------------\n","aug_rows = []\n","for key in df[\"_class_key\"].unique():\n","    grp = df[df[\"_class_key\"] == key]\n","    if len(grp) == 0:\n","        continue\n","    seeds = grp.to_dict(\"records\")\n","    to_add = N_ADD_PER_CLASS\n","    error_budget = int(round(to_add * ERROR_RATE))\n","    errors_made = 0\n","    attempts = 0\n","\n","    while to_add \u003e 0 and attempts \u003c 20000:\n","        attempts += 1\n","        seed = random.choice(seeds)\n","        new_row = dict(seed)\n","\n","        # ปรับแต่งเฉพาะคอลัมน์ใน TARGET_COLS ที่มีอยู่จริงในไฟล์\n","        for col in TARGET_COLS:\n","            v = seed.get(col, \"\")\n","            v = str(v)\n","            if col.lower() == \"dosage_strength\":\n","                v = vary_dosage_strength(v)\n","            else:\n","                v = apply_synonyms(v)\n","                v = tweak_numbers(v)\n","\n","            new_row[col] = v\n","\n","        # เพิ่ม error ไม่เกิน budget\n","        if errors_made \u003c error_budget and random.random() \u003c 0.10:\n","            err_col = random.choice(TARGET_COLS)\n","            new_row[err_col] = small_typo(new_row.get(err_col, \"\"))\n","            errors_made += 1\n","\n","        aug_rows.append(new_row)\n","        to_add -= 1\n","\n","# รวมเป็น DataFrame\n","aug_df = pd.DataFrame(aug_rows)\n","\n","# รวมข้อมูลเดิม + ใหม่\n","final_df = pd.concat([df, aug_df], ignore_index=True)\n","\n","# บันทึก\n","final_df.to_excel(OUT_PATH, index=False)\n","print(f\"✅ Done! Saved to {OUT_PATH}\")\n"]},{"cell_type":"markdown","id":"be369e78-45e7-4911-8faf-f02e2053185b","metadata":{"id":"be369e78-45e7-4911-8faf-f02e2053185b"},"source":["# Train Data Set New"]},{"cell_type":"code","execution_count":null,"id":"25244574-98ef-41f3-9248-3f1fdeb057ea","metadata":{"colab":{"background_save":true},"id":"25244574-98ef-41f3-9248-3f1fdeb057ea"},"outputs":[],"source":["# เช็คตัวแปรในไฟล์ที่ดึงมา\n","import pandas as pd\n","\n","df = pd.read_excel(\"leaflet_train.xlsx\")\n","print(df.columns.tolist())\n"]},{"cell_type":"code","execution_count":null,"id":"1a988d15-5f30-4a3f-9ffa-77e7ce256db7","metadata":{"colab":{"background_save":true},"id":"1a988d15-5f30-4a3f-9ffa-77e7ce256db7","scrolled":true},"outputs":[],"source":["# อ่านข้อมูลจากไฟล์\n","df = pd.read_excel(\"leaflet_train.xlsx\")\n","\n","# ตรวจสอบข้อมูลเบื้องต้น\n","print(df.head())\n","print(df.info())\n"]},{"cell_type":"code","execution_count":null,"id":"2c735f93-a43f-4024-ada7-d0d4a742886b","metadata":{"colab":{"background_save":true},"id":"2c735f93-a43f-4024-ada7-d0d4a742886b","scrolled":true},"outputs":[],"source":["# ใช้ทำกราฟ\n","!pip install seaborn\n"]},{"cell_type":"code","execution_count":null,"id":"52ada850-a7cd-4934-aea8-3198504a774c","metadata":{"colab":{"background_save":true},"id":"52ada850-a7cd-4934-aea8-3198504a774c"},"outputs":[],"source":["# นำเข้าชุดเครื่องมือหลัก: แบ่งเทรน/ทดสอบ, TF‑IDF, โมเดล, metric, กราฟ, และตัวช่วย oversampling\n","import pandas as pd\n","import numpy as np\n","import random\n","import re\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from imblearn.over_sampling import RandomOverSampler\n"]},{"cell_type":"code","execution_count":null,"id":"c7f5801d-a6ec-4e84-a16d-96d65a5c3722","metadata":{"colab":{"background_save":true},"id":"c7f5801d-a6ec-4e84-a16d-96d65a5c3722"},"outputs":[],"source":["# กำหนดคอลัมน์ที่ต้องการรวมเป็นข้อความ\n","text_cols = ['generics', 'dosage_strengths', 'indications', 'instructions', 'warnings']\n","\n","# แปลงเป็นสตริงและ สตริงว่างเติมค่าแทน NaN ก่อนรวม\n","for c in text_cols:\n","    df[c] = df[c].fillna('').astype(str)\n","\n","# รวมข้อความเป็นคอลัมน์text\n","df['text'] = df[text_cols].agg(' '.join, axis=1)\n","\n","# เอาเฉพาะแถวที่มี label (generics) จริง ๆ\n","df = df[df['generics'].str.strip() != '']"]},{"cell_type":"code","execution_count":null,"id":"5de45e3d-fd7f-46a9-a643-684d90ced8db","metadata":{"colab":{"background_save":true},"id":"5de45e3d-fd7f-46a9-a643-684d90ced8db"},"outputs":[],"source":["from imblearn.over_sampling import RandomOverSampler"]},{"cell_type":"code","execution_count":null,"id":"6a3f5ab7-1460-4e72-bde6-263c623b3d98","metadata":{"colab":{"background_save":true},"id":"6a3f5ab7-1460-4e72-bde6-263c623b3d98"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression"]},{"cell_type":"code","execution_count":null,"id":"2c3e213a-accb-4a46-afbc-65db0e1b82d6","metadata":{"colab":{"background_save":true},"id":"2c3e213a-accb-4a46-afbc-65db0e1b82d6"},"outputs":[],"source":["X = df['text']\n","y = df['generics']\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.3, stratify=y, random_state=42\n",")\n"]},{"cell_type":"code","execution_count":null,"id":"a82ba548-6cf6-400e-b178-5afa8299b051","metadata":{"colab":{"background_save":true},"collapsed":true,"id":"a82ba548-6cf6-400e-b178-5afa8299b051","scrolled":true},"outputs":[],"source":["vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n","X_train_tfidf = vectorizer.fit_transform(X_train)\n","X_test_tfidf  = vectorizer.transform(X_test)\n","\n","from imblearn.over_sampling import RandomOverSampler\n","ros = RandomOverSampler(random_state=42)\n","X_resampled, y_resampled = ros.fit_resample(X_train_tfidf, y_train)\n","\n","from sklearn.linear_model import LogisticRegression\n","model = LogisticRegression(solver='saga', max_iter=300, tol=1e-3)\n","model.fit(X_resampled, y_resampled)\n","\n","y_pred = model.predict(X_test_tfidf)\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(classification_report(y_test, y_pred, digits=4, zero_division=0))\n"]},{"cell_type":"code","execution_count":null,"id":"c8c8af47-f0a9-4b30-9a11-d9d2cba2fe1e","metadata":{"colab":{"background_save":true},"id":"c8c8af47-f0a9-4b30-9a11-d9d2cba2fe1e"},"outputs":[],"source":["if 'df' not in globals():\n","    import pandas as pd\n","    df = pd.read_excel('leaflet_train.xlsx')\n","\n","need_text = 'text' not in df.columns\n","if need_text:\n","    for c in ['generics','dosage_strengths','indications','instructions','warnings']:\n","        if c in df.columns:\n","            df[c] = df[c].fillna('').astype(str)\n","        else:\n","            df[c] = ''  # กันพลาดกรณีคอลัมน์ขาด\n","    df['text'] = (df['generics'] + ' ' + df['dosage_strengths'] + ' ' +\n","                  df['indications'] + ' ' + df['instructions'] + ' ' +\n","                  df['warnings'])\n","\n","if 'X_train' not in globals() or 'y_train' not in globals():\n","    from sklearn.model_selection import train_test_split\n","    X = df['text']\n","    y = df['generics'].astype(str)\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=0.3, stratify=y, random_state=42\n","    )\n","\n","if 'X_train_tfidf' not in globals():\n","    from sklearn.feature_extraction.text import TfidfVectorizer\n","    vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1,2))\n","    X_train_tfidf = vectorizer.fit_transform(X_train)\n","\n","random_state=42 #เพื่อให้ผล oversampling ทำซ้ำได้\n","from imblearn.over_sampling import RandomOverSampler\n","ros = RandomOverSampler(random_state=42)\n","X_resampled, y_resampled = ros.fit_resample(X_train_tfidf, y_train)\n","\n","\n","print(\"X_resampled:\", X_resampled.shape, \"| y_resampled:\", y_resampled.shape)\n"]},{"cell_type":"code","execution_count":null,"id":"97a79b86-6db0-4f0e-88ee-8d72d4ecaa95","metadata":{"colab":{"background_save":true},"id":"97a79b86-6db0-4f0e-88ee-8d72d4ecaa95","scrolled":true},"outputs":[],"source":["whos"]},{"cell_type":"markdown","id":"1d4cb53e-38e0-45f0-912d-65875e5928e0","metadata":{"id":"1d4cb53e-38e0-45f0-912d-65875e5928e0"},"source":["# Epoch Data Set Augmeatation"]},{"cell_type":"code","execution_count":null,"id":"f689e41a-4ca0-4f2a-be2e-c99a62a84622","metadata":{"colab":{"background_save":true},"id":"f689e41a-4ca0-4f2a-be2e-c99a62a84622"},"outputs":[],"source":["# 1) แบ่ง Train/Validation จากชุดที่ oversample มาแล้ว\n","X_tr, X_val, y_tr, y_val = train_test_split(\n","    X_resampled, y_resampled, test_size=0.3, random_state=42, stratify=y_resampled\n",")"]},{"cell_type":"code","execution_count":null,"id":"6b285002-cf3a-4279-acea-19578439a130","metadata":{"colab":{"background_save":true},"id":"6b285002-cf3a-4279-acea-19578439a130"},"outputs":[],"source":["import pandas as pd\n","df = pd.read_excel(\"leaflet_train.xlsx\")\n","print(\"ใช้ข้อมูลจาก: leaflet_train.xlsx\")\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, log_loss\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","\n","\n","# 2) ตั้งค่า Logistic Regression (เทรนแบบ incremental)\n","epochs = 10  # จำนวนรอบเทรน\n","model_epoch = LogisticRegression(\n","    solver='saga',         # รองรับ sparse matrix ได้ดี\n","    penalty='l2',          # เพิ่ม regularization ให้เสถียร\n","    C=1.0,                 # ลดค่าถ้า overfitting (0.5, 0.1)\n","    max_iter=1,            # เทรนครั้งละ 1 iteration ต่อ epoch\n","    warm_start=True,       # ต่อจากน้ำหนักเดิมทุก epoch\n","    n_jobs=-1,             # ใช้หลาย core เพื่อความเร็ว\n","    random_state=42\n",")\n","\n","train_loss, val_loss, train_acc, val_acc = [], [], [], []\n","\n","# 3) วนเทรนหลาย epoch\n","for ep in range(1, epochs+1):\n","    model_epoch.fit(X_tr, y_tr)\n","\n","    # ---- Train metrics ----\n","    ytr_pred = model_epoch.predict(X_tr)\n","    ytr_prob = model_epoch.predict_proba(X_tr)\n","    acc_tr   = accuracy_score(y_tr, ytr_pred)\n","    loss_tr  = log_loss(y_tr, ytr_prob, labels=model_epoch.classes_)\n","\n","    # ---- Validation metrics ----\n","    yv_pred = model_epoch.predict(X_val)\n","    yv_prob = model_epoch.predict_proba(X_val)\n","    acc_val = accuracy_score(y_val, yv_pred)\n","    loss_val = log_loss(y_val, yv_prob, labels=model_epoch.classes_)\n","\n","    # ---- เก็บค่า ----\n","    train_acc.append(acc_tr)\n","    val_acc.append(acc_val)\n","    train_loss.append(loss_tr)\n","    val_loss.append(loss_val)\n","\n","    print(f\"Epoch {ep:02d}/{epochs} | \"\n","          f\"acc_tr={acc_tr:.4f} acc_val={acc_val:.4f} | \"\n","          f\"loss_tr={loss_tr:.4f} loss_val={loss_val:.4f}\")\n","\n","# 4) กราฟ Loss ต่อ epoch\n","plt.figure(figsize=(9,4))\n","plt.plot(range(1, epochs+1), train_loss, marker='o', label='Training Loss')\n","plt.plot(range(1, epochs+1), val_loss, marker='o', label='Validation Loss')\n","plt.title('Log Loss per Epoch')\n","plt.xlabel('Epoch'); plt.ylabel('Log Loss')\n","plt.grid(True); plt.legend(); plt.show()\n","\n","# 5) กราฟ Accuracy ต่อ epoch\n","plt.figure(figsize=(9,4))\n","plt.plot(range(1, epochs+1), train_acc, marker='o', label='Training Accuracy')\n","plt.plot(range(1, epochs+1), val_acc, marker='o', label='Validation Accuracy')\n","plt.title('Accuracy per Epoch')\n","plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n","plt.grid(True); plt.legend(); plt.show()\n","\n","from sklearn.metrics import classification_report\n","\n"]},{"cell_type":"markdown","id":"775d75dc-d633-418a-8889-11e2bcea05a6","metadata":{"id":"775d75dc-d633-418a-8889-11e2bcea05a6"},"source":["## ปรับปรุงกราฟของ Data Set Augmentation\n","###### log_loss เพี้ยน เพราะใช้ labels ไม่ตรงกับลำดับโปรบาบิลิตี\n","###### predict_proba ของโมเดลเรียงคอลัมน์ตาม sgd.classes_\n","###### ชุดที่ใช้วัดผลไม่ชัด (ตัวแปร X_tr/X_val) อ้าง X_tr, y_tr, X_val, y_val แต่ไม่ได้ล็อกนิยามให้ชัดเจน\n","###### กำหนด classes = np.unique(y_resampled) อาจไม่ครอบคลุมคลาสใน y_val บางตัว"]},{"cell_type":"code","execution_count":null,"id":"7e99652b-65e6-44b2-992b-f14d8ef5e68f","metadata":{"colab":{"background_save":true},"id":"7e99652b-65e6-44b2-992b-f14d8ef5e68f"},"outputs":[],"source":["from sklearn.linear_model import SGDClassifier\n","from sklearn.metrics import accuracy_score, log_loss\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# ===== ตั้งค่า =====\n","epochs = 10\n","batch_size = 2048\n","classes = np.unique(y_resampled)\n","\n","# ===== โมเดล =====\n","sgd = SGDClassifier(\n","    loss='log_loss',\n","    alpha=1e-4,\n","    learning_rate='optimal',\n","    early_stopping=False,\n","    class_weight=None,\n","    random_state=42\n",")\n","\n","# ===== เตรียมเก็บค่าเพื่อพล็อต =====\n","train_acc_list, val_acc_list = [], []\n","train_loss_list, val_loss_list = [], []\n","\n","# ===== เริ่มเทรน =====\n","n = X_resampled.shape[0]\n","for ep in range(1, epochs+1):\n","    # shuffle index ทุก epoch\n","    idx = np.random.permutation(n)\n","    X_shuf = X_resampled[idx]\n","    y_shuf = y_resampled.iloc[idx] if hasattr(y_resampled, \"iloc\") else y_resampled[idx]\n","\n","    # mini-batch training\n","    start = 0\n","    while start \u003c n:\n","        end = min(start + batch_size, n)\n","        Xb, yb = X_shuf[start:end], y_shuf[start:end]\n","        if ep == 1 and start == 0:\n","            sgd.partial_fit(Xb, yb, classes=classes)\n","        else:\n","            sgd.partial_fit(Xb, yb)\n","        start = end\n","\n","    # ==== คำนวณ metric ต่อ epoch ====\n","    ytr = sgd.predict(X_tr)\n","    ytrp = sgd.predict_proba(X_tr)\n","    yv = sgd.predict(X_val)\n","    yvp = sgd.predict_proba(X_val)\n","\n","    acc_tr = accuracy_score(y_tr, ytr)\n","    acc_val = accuracy_score(y_val, yv)\n","    loss_tr = log_loss(y_tr, ytrp, labels=classes)\n","    loss_val = log_loss(y_val, yvp, labels=classes)\n","\n","    train_acc_list.append(acc_tr)\n","    val_acc_list.append(acc_val)\n","    train_loss_list.append(loss_tr)\n","    val_loss_list.append(loss_val)\n","\n","    print(f\"[SGD] Epoch {ep:02d}/{epochs} | \"\n","          f\"acc_tr={acc_tr:.6f} acc_val={acc_val:.6f} | \"\n","          f\"loss_tr={loss_tr:.6f} loss_val={loss_val:.6f}\")\n","\n","# ===== พล็อตกราฟหลังเทรนเสร็จ =====\n","epochs_range = range(1, epochs + 1)\n","\n","# --- Loss ---\n","plt.figure(figsize=(9,4))\n","plt.plot(epochs_range, train_loss_list, marker='o', label='Training Loss')\n","plt.plot(epochs_range, val_loss_list, marker='o', label='Validation Loss')\n","plt.title('SGDClassifier - Log Loss per Epoch')\n","plt.xlabel('Epoch')\n","plt.ylabel('Log Loss')\n","plt.grid(True)\n","plt.legend()\n","plt.show()\n","\n","# --- Accuracy ---\n","plt.figure(figsize=(9,4))\n","plt.plot(epochs_range, train_acc_list, marker='o', label='Training Accuracy')\n","plt.plot(epochs_range, val_acc_list, marker='o', label='Validation Accuracy')\n","plt.title('SGDClassifier - Accuracy per Epoch')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.grid(True)\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"7ca39d6e-7471-48b4-9ac9-e1b816749199","metadata":{"colab":{"background_save":true},"id":"7ca39d6e-7471-48b4-9ac9-e1b816749199"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"ee347ada-ead2-4a4f-baf8-4eb07cf3f0e7","metadata":{"id":"ee347ada-ead2-4a4f-baf8-4eb07cf3f0e7"},"source":["### Play Model"]},{"cell_type":"code","execution_count":null,"id":"d5dbf933-d872-4e5f-a686-37aff75a9abd","metadata":{"colab":{"background_save":true},"id":"d5dbf933-d872-4e5f-a686-37aff75a9abd"},"outputs":[],"source":["import joblib\n","\n","joblib.dump(model, 'leaflet_realdatad.joblib')\n","joblib.dump(vectorizer, 'leaflet_realdatad1.joblib')\n","\n","print(\"บันทึกโมเดลและเวกเตอร์ไรเซอร์เรียบร้อย\")\n"]},{"cell_type":"code","execution_count":null,"id":"2Pl_tS6bn188","metadata":{"colab":{"background_save":true},"id":"2Pl_tS6bn188"},"outputs":[],"source":["from google.colab import files\n","files.download(\"leaflet_realdatad.joblib\")\n","files.download(\"leaflet_realdatad1.joblib\")\n","\n"]},{"cell_type":"code","execution_count":null,"id":"ea552c91-c0cf-48cd-9572-147b8afe759b","metadata":{"colab":{"background_save":true},"id":"ea552c91-c0cf-48cd-9572-147b8afe759b"},"outputs":[],"source":["# ====== เตรียมรายชื่อยา (ดึงจาก DataFrame) ======\n","# สมมุติว่าคุณมี df จาก leaflet_train.xlsx อยู่แล้ว และคอลัมน์ชื่อยา = 'generics'\n","generics_list = (\n","    df['generics']\n","    .dropna()\n","    .astype(str)\n","    .str.strip()\n","    .str.lower()             # ไม่สนพิมพ์เล็กใหญ่\n","    .unique()\n","    .tolist()\n",")\n","\n","# ====== เวกเตอร์ไรซ์ด้วย character n-grams (เหมาะกับ partial match/ภาษาไทย) ======\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import linear_kernel\n","import numpy as np\n","\n","# char_wb จะใส่ช่องว่าง padding ให้จับคำย่อยได้ดีขึ้น; n-grams 2–5 ช่วยทั้งไทย/อังกฤษ\n","char_vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(2,5))\n","G = char_vectorizer.fit_transform(generics_list)  # ขนาด: n_generics x n_features\n","\n","def search_generic_partial(query, topk=5, threshold=0.5):\n","    \"\"\"\n","    คืน candidate top-k ตาม cosine similarity\n","    - query: string (เช่น 'พารา', 'para', 'amlod', ...)\n","    - threshold: รับผลเฉพาะที่ similarity \u003e= threshold\n","    \"\"\"\n","    q = str(query).strip().lower()\n","    if not q:\n","        return []\n","\n","    qv = char_vectorizer.transform([q])\n","    sims = linear_kernel(qv, G)[0]   # cosine similarity ต่อ generic แต่ละตัว\n","    idx = np.argsort(-sims)[:topk]\n","    results = [(generics_list[i], float(sims[i])) for i in idx if sims[i] \u003e= threshold]\n","    return results\n","\n","# ====== ตัวอย่างทดลอง ======\n","print(\"ค้นหา: 'para'  → \", search_generic_partial(\"para\", topk=5, threshold=0.25))\n","print(\"ค้นหา: 'Eugnol'  → \", search_generic_partial(\"Eugnol\", topk=5, threshold=0.5))\n","print(\"ค้นหา: 'Amlodipine' → \", search_generic_partial(\"Amlodipine\", topk=3, threshold=0.5))\n","#print(search_generic_partial(\"Eunol\", topk=5, threshold=0.3))\n","#print(search_generic_partial(\"Eugnol\", topk=5, threshold=0.3))\n","#print(search_generic_partial(\"Amlodipine\", topk=5, threshold=0.3))\n","#print(search_generic_partial(\"พารา\", topk=5, threshold=0.3))\n"]},{"cell_type":"code","execution_count":null,"id":"cf2fa50f-7790-4c1d-be5f-b05252fecd0a","metadata":{"colab":{"background_save":true},"id":"cf2fa50f-7790-4c1d-be5f-b05252fecd0a"},"outputs":[],"source":["# ====== เตรียมข้อมูลจาก DataFrame ======\n","# df ต้องมีคอลัมน์: generics, strength, indication, dosage, warning\n","generics_list = (\n","    df['generics']\n","    .dropna()\n","    .astype(str)\n","    .str.strip()\n","    .str.lower()\n","    .unique()\n","    .tolist()\n",")\n","\n","# ====== TF-IDF สำหรับ partial match ======\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import linear_kernel\n","import numpy as np\n","\n","char_vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(2,5))\n","G = char_vectorizer.fit_transform(generics_list)\n","\n","def search_generic_detailed(query, topk=5, threshold=0.3):\n","    q = str(query).strip().lower()\n","    if not q:\n","        return \"⚠️ กรุณากรอกชื่อยาที่ต้องการค้นหา\"\n","\n","    qv = char_vectorizer.transform([q])\n","    sims = linear_kernel(qv, G)[0]\n","    idx = np.argsort(-sims)[:topk]\n","    results = [(generics_list[i], float(sims[i])) for i in idx if sims[i] \u003e= threshold]\n","    if not results:\n","        return \"❌ ไม่พบยาที่ใกล้เคียง\"\n","\n","    print(f\"\\n🔍 ค้นหา: {query}\\n{'='*60}\")\n","\n","    # ====== แสดงผลอันดับ 1 ======\n","    top1 = results[0]\n","    top1_name, top1_sim = top1\n","    row = df[df['generics'].str.lower().str.strip() == top1_name].head(1)\n","\n","    if not row.empty:\n","        print(f\" ชื่อยา: {top1_name.title()} ({top1_sim*100:.2f}%)\")\n","        #print(f\"   ปริมาณ: {row.iloc[0].get('dosage_strengths', '-')}\")\n","        print(f\"   สรรพคุณ: {row.iloc[0].get('indications', '-')}\")\n","        print(f\"   วิธีใช้: {row.iloc[0].get('instructions', '-')}\")\n","        print(f\"   ข้อควรระวัง: {row.iloc[0].get('warnings', '-')}\")\n","    else:\n","        print(f\" ชื่อยา: {top1_name.title()} ({top1_sim*100:.2f}%)\")\n","        print(\"   ⚠️ ไม่พบรายละเอียดในฐานข้อมูล\")\n","\n","    # ====== แสดงอันดับ 2–3 (เฉพาะชื่อและ%) ======\n","    for rank, (name, sim) in enumerate(results[1:], start=2):\n","        print(f\"{rank}. ชื่อยา: {name.title()} ({sim*100:.2f}%)\")\n","\n","# ====== ทดลองค้นหา ======\n","search_generic_detailed(\"systemic\")\n","search_generic_detailed(\"พาเซมอล\")\n","search_generic_detailed(\"Amlodipine\")\n"]},{"cell_type":"code","execution_count":null,"id":"FIYMsM53_aPH","metadata":{"colab":{"background_save":true},"id":"FIYMsM53_aPH"},"outputs":[],"source":["# โค้ดที่ปรับปรุงให้ขึ้นว่าไม่เจอเมื่อไม่มีคลาส"]},{"cell_type":"code","execution_count":null,"id":"ZiTyzT2m_Enf","metadata":{"colab":{"background_save":true},"id":"ZiTyzT2m_Enf"},"outputs":[],"source":["def search_generic_detailed(query, topk=5, threshold=0.3, verbose=True):\n","    q = str(query).strip().lower()\n","    if not q:\n","        msg = \"⚠️ กรุณากรอกชื่อยาที่ต้องการค้นหา\"\n","        return print(msg) if verbose else msg\n","\n","    qv = char_vectorizer.transform([q])\n","    sims = linear_kernel(qv, G)[0]\n","    idx = np.argsort(-sims)[:topk]\n","    results = [(generics_list[i], float(sims[i])) for i in idx if sims[i] \u003e= threshold]\n","\n","    # ---- กรณีไม่เจออะไรเลย (เพราะ threshold เข้มงวดเกิน / คำไม่คล้าย) ----\n","    if not results:\n","        msg = \"❌ ไม่พบรายละเอียดในฐานข้อมูล\"\n","        return print(msg) if verbose else msg\n","\n","    print(f\"\\n🔍 ค้นหา: {query}\\n{'='*60}\")\n","\n","    # ====== แสดงผลอันดับ 1 ======\n","    top1_name, top1_sim = results[0]\n","    row = df[df['generics'].str.lower().str.strip() == top1_name].head(1)\n","\n","    if not row.empty:\n","        print(f\" ชื่อยา: {top1_name.title()} ({top1_sim*100:.2f}%)\")\n","        print(f\"   สรรพคุณ: {row.iloc[0].get('indications', '-')}\")\n","        print(f\"   วิธีใช้: {row.iloc[0].get('instructions', '-')}\")\n","        print(f\"   ข้อควรระวัง: {row.iloc[0].get('warnings', '-')}\")\n","    else:\n","        # ---- กรณีมีชื่อที่คล้าย แต่ไม่มีรายละเอียดใน df ----\n","        print(f\" ชื่อยา: {top1_name.title()} ({top1_sim*100:.2f}%)\")\n","        print(\"   ❌ ไม่พบรายละเอียดในฐานข้อมูล\")\n","\n","    # ====== แสดงอันดับ 2–3 (เฉพาะชื่อและ%) ======\n","    for rank, (name, sim) in enumerate(results[1:], start=2):\n","        print(f\"{rank}. ชื่อยา: {name.title()} ({sim*100:.2f}%)\")\n","\n","search_generic_detailed(\"systemic\")\n","search_generic_detailed(\"Amlo\")\n","search_generic_detailed(\"para\")\n"]},{"cell_type":"markdown","id":"8209c807-7074-449e-a7b9-5158f3d18883","metadata":{"id":"8209c807-7074-449e-a7b9-5158f3d18883"},"source":["# Model Training\n","-**อัตราส่วนข้อมูลที่ใช้ train : 70,30   seed 42**"]},{"cell_type":"markdown","id":"4242a1fb-bded-4ba8-a170-cd9ce391fa8d","metadata":{"id":"4242a1fb-bded-4ba8-a170-cd9ce391fa8d"},"source":["#  การประเมินผลหลังปรับปรุง\n","\n","-**Data (Cleaning)**\n","-**Accuracy: 0.8097345132743363 (ทั้งโมเดล)**\n","-**Accuracy 0.5713 : Loss 1.3683 (epoch ก่อนปรับปรุง)**\n","-**Accuracy 0.903757 : Loss 1.872916 (epoch หลังปรับปรุง)**\n","\n","-**Data (augmentation)**\n","-**Accuracy: 0.9732547415694294 ทั้งโมเดล**\n","-**Accuracy 0.9504 : Loss 0.2288 -epochก่อนปรับปรุง**\n","-**Accuracy 0.946133 : Loss 1.663804 -epochหลังปรับปรุง**\n"]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"nbformat":4,"nbformat_minor":5}